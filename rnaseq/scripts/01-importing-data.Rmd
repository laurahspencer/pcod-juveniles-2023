---
title: "01-importing-data"
author: "Laura Spencer"
date: '2024-04-05'
output:
  html_document:
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
      number_sections: true
---

In this notebook I will import gene counts file that were generated by STAR 

### Check working directory 

```{r}
getwd()
```

### Load libraries and source scripts 

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}

# source("../references/biostats.R")

# Add all required libraries that are installed with install.packages() here
list.of.packages <- c("RCurl", "tidyverse", "vegan", "pheatmap", "pastecs", "factoextra", "FactoMineR", "RColorBrewer", "tibble", "reshape2", "plotly", "corrplot", "PerformanceAnalytics", "cowplot", "here", "janitor", "clipr", "googlesheets4")
# Add all libraries that are installed using BiocManager here
bioconductor.packages <- c("DESeq2", "WGCNA")

# Install BiocManager if needed
if(!requireNamespace("BiocManager", quietly = TRUE)) install.packages("BiocManager")

# Get names of all required packages that aren't installed
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[, "Package"])]
new.bioc.packages <- bioconductor.packages[!(bioconductor.packages %in% installed.packages()[, "Package"])]
# Install all new packages
if(length(new.packages)) install.packages(new.packages)
if(length(new.bioc.packages)) BiocManager::install(new.bioc.packages)

# Load all required libraries
all.packages <- c(list.of.packages, bioconductor.packages)
lapply(all.packages, FUN = function(X) {
  do.call("require", list(X))
})

```

### Import sample info, library/file names, and then join 

NOTE: data is read directly from the GoogleSheet using a share link that was set to "anyone with a link can view"
 

```{r}
# library.stats <- read.csv("../data/library-prep-stats.csv", header=T) %>% clean_names %>%
#   dplyr::mutate_at(vars(tank_number, p_h, batch, date_extracted), as.factor)

# Read in sample key
sample.info <- read_delim("../../data/DESeq2_Sample_Information.txt", delim="\t") %>% 
  clean_names() %>% 
  mutate_at(vars(tank, temp_treatment, tissue_type), as.factor) %>%
  rename("temp_treatment"="temperature", "tank"="tank_number") %>%
  mutate(temperature_tank=factor(paste(temperature, tank_number, sep="_")))

save(sample.info, file="../sample.info")
```

### Import library stats from MultiQC and from library prep

```{r}
multiqc.stats <- read.delim(file="../aligned/multiqc_star.txt", sep = "\t")
multiqc.stats <- multiqc.stats %>% clean_names() %>%
  left_join(sample.info %>% mutate(sample=as.character(sample_number)))
```

### Investigate possible correlations among # reads and prep stuff 

```{r}
cor(multiqc.stats %>% mutate(tank_number=as.numeric(tank_number)) %>% dplyr::select_if(is.numeric), use="complete.obs") %>% corrplot::corrplot(tl.cex=.75)
```

### Import count data

#### Import data generated directly using the  STAR aligner step 

#### Generate tab-separated file that lists file names

```{bash}
rm ../aligned/countsfilenames.txt #rm file if it already exists
for file in ../aligned/*.ReadsPerGene.out.tab
do
filename="$(echo $file)"
sample="$(basename -a $filename | cut -d "." -f 1)"
printf "%s\t%s\n" "$filename" "sample_$sample" >> ../aligned/countsfilenames.txt
done
```

#### Confirm filenamems look good

```{bash}
head ../aligned/countsfilenames.txt
wc -l ../aligned/countsfilenames.txt
```

```{r}
# Using STAR aligned and STAR quantified counts
filenames <- read_delim(file="../aligned/countsfilenames.txt", col_names = c("filename", "sample"), delim = "\t")
files <- file.path(filenames$filename) #extract vector of filenames
all(file.exists(files)) #easy code to check that all files exist!

file_list <- vector(mode = "list", length = nrow(filenames))
names(file_list) <- c(filenames$sample)

for (i in 1:nrow(filenames)) {
    file_list[[i]] <- data.frame(read.delim(file=files[i]))[-1:-4,1:2]
    names(file_list[[i]]) <- c("gene", filenames$sample[i])
    print(paste("Total COUNTS,", names(file_list[[i]][2]), ":", prettyNum(sum(file_list[[i]][2]), big.mark=","), sep=" "))
    print(paste("Total GENES,", names(file_list[[i]][2]), ":", prettyNum(nrow(file_list[[i]] %>% filter(.[[2]] != 0)), big.mark=","), sep=" "))
}

(counts.star <- file_list %>% purrr::reduce(full_join, by = "gene") %>% column_to_rownames(var="gene"))
```

<!-- ### Import counts generated using featurecounts from star alignments -->

<!-- ```{r} -->
<!-- counts.fc <- data.frame(read.table("../results/star/featurecounts/featurecounts_gene", header = T, stringsAsFactors = F, fill = FALSE)) %>% -->
<!--   column_to_rownames(var="Geneid") -->
<!-- counts.fc <- counts.fc %>% rename_all(~as.character(str_sub(colnames(counts.fc)) %>% -->
<!--                             gsub("X.home.lspencer.pcod.2022.aligned.star.gadmor.", "", .) %>% -->
<!--                             gsub(".Aligned.sortedByCoord.out.bam", "", .))) %>% select(-Chr, -Start, -End, -Strand, -Length) -->
<!-- save(counts.fc, file = "../results/star/featurecounts/counts.fc") -->
<!-- ``` -->

### Decide which source of counts you'd like to use! (NOTE- they both are derived from STAR aligner)

```{r}
#counts <- counts.fc
counts <- counts.star
```


### Summarize counts and visualize (remove last column - that's undetermined counts)

```{r}
print(paste("Number of samples:", ncol(counts %>% dplyr::select(contains("sample"))), sep=" "))
print(paste("Total number of genes in dataframe:", prettyNum(nrow(counts), big.mark = ","), sep=" "))
print(paste("Average number of genes per sample:", prettyNum(mean(colSums(counts %>% dplyr::select(contains("sample")) != 0)) %>% round(), big.mark = ","), sep=" "))
print(paste("Total counts, all samples:", prettyNum(sum(colSums(counts %>% dplyr::select(contains("sample")))), big.mark = ","), sep=" "))
#print(paste("Counts for", colnames(counts %>% select(contains("PCG"))), ":",  prettyNum(colSums(counts %>% select(contains("PCG"))), big.mark = ","), sep=" "))

#inspect total counts by sample 
# sample 149 very high 
# sample 129 kinda low
ggplotly(
   ggplot(data.frame(colSums(counts %>% dplyr::select(contains("sample")))) %>% 
            dplyr::rename(count.total = 1) %>% rownames_to_column(var="sample")) + 
     geom_bar(aes(x=sample, y=count.total), stat = "identity") + ggtitle("Total count by sample") + 
              theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())) 
```

## OPTIONAL: FILTER WHOLE SAMPLES. 

Remove whole samples from the data set and sample info here if needed

USE THIS CODE TO REMOVE SPLEEN AND GILL SAMPLES FOR THIS ANALYSIS, LEAVE ONLY LIVER SAMPLES 

```{r}
outliers <- c("sample_31", "sample_41", "sample_149")
remove.list <- c(counts %>% select(contains(c("-S", "-G"))) %>% colnames(), outliers)
counts <- counts[ , which(names(counts) %!in% remove.list)]

# need to remove "RESUB-" from some sample names 
sample.info <- sample.info %>% mutate(sample_name=gsub("RESUB-", "", sample_name)) %>% filter(sample_name %in% colnames(counts))

nrow(sample.info) == ncol(counts) #should = TRUE
all(sort(sample.info$sample_name) == sort(colnames(counts))) #should = TRUE

# resave sample info object
save(sample.info, file="../sample.info")
```

USE THIS CODE TO REMOVE OUTLIER SAMPLES BY NAME 

```{r}
# remove.list <- c("PCG194", "PCG137")
# counts <- counts[ , -which(names(counts) %in% remove.list)]
# sample.info <- sample.info[ -which(sample.info$sample_name %in% remove.list), ]
# 
# # resave sample info object
# save(sample.info, file="../data/sample.info")
# 
# nrow(sample.info) == ncol(counts) #should = TRUE
```

## OPTIONAL: FILTER WHOLE SCAFFOLDS 

This code provides the option to remove data that mapped to scaffolds 105+. This is possibly beneficial because I don't know whether or not those scaffolds are also included within scaffolds 1-104 (i.e. the chromosomes). 

NOTE:  For exploration purposes I will NOT remove them, and will see if expressed data mapping to scaffolds 105+ have the exact same genes/counts as on chromosomes. 

After preliminary examination of blast results (by looking at genes, lengths, and counts) it's difficult to tell whether the scaffolds 105+ are subsets of the chromosomes 1-104. For now I will retain scaffolds 105+. 


```{r}
# counts <- counts %>% separate(Chr, into = c("X", "Y", "scaffold"), sep = "_", remove = F) %>%
#   mutate(scaffold=as.integer(scaffold)) %>% filter(scaffold<=104) %>% dplyr::select(-X, -Y, -scaffold)
```

### Optional: FILTER GENES THAT ARE OUTLIERS IN OUTLIER SAMPLES- NOT USED AS OF 12/2/2022

```{r}
# counts <- counts[-which(rownames(counts) %in% outliers),]
```

### Transpose dataframe so each row = a sample (aka "objects"), and each column = genes (aka "variables") 
```{r}
#str(counts) #columns #1-#5 contain extraneous gene info (chr, start, end, strand, length). 
counts.t <- as.data.frame(t(counts)) #remove extraneous columns, transform data to have each sample a row, each column a gene
```

## Optional 

### Pre-filtering - remove low-frequency genes 

NOTE: Should i do this? DESeq2 throws out low-frequency genes anyway, BUT other folks do pre-filter. For example in https://doi.org/10.1186/s12864-017-4392-0 "Genes with mean count less than ten across all samples were removed."

```{r}
keep1 <- colMeans(counts.t, na.rm=TRUE) >= 10 #identify genes with mean count >= 10 across all samples (excluding NAs = 10)
keep2 <- rowSums( counts >= 30 ) >= 0.1*79 #identify genes with counts>=30 across at minimum 10% of the samples
keep <- unique(c(names(which(keep1 == T)), names(which(keep2 == T)))) # list of genes meeting one of the two above criteria
counts.ts <- counts.t[,keep]

print(paste("# genes before filtering:", ncol(counts.t)))
print(paste("# genes remaining after pre-filtering:", ncol(counts.ts)))
print(paste("# of genes dropped:", ncol(counts.t) - ncol(counts.ts), sep=" "))
print(paste("% of fragments remaining after pre-filtering: ", signif(100*sum(counts.ts)/sum(counts.t), digits = 5), "%", sep=""))
print(paste("Number of fragments dropped: ", signif(sum(counts.t)-sum(counts.ts), digits = 5)))
print(paste("% of fragments dropped: ", signif(100*(sum(counts.t)-sum(counts.ts))/sum(counts.t), digits = 5), "%", sep=""))
print(paste("Number of fragments remaining: ", signif(sum(counts.ts), digits = 5)))
```
### Save counts file, and transformed counts file 
```{r}
save(counts, file = "../counts")
save(counts.t, file = "../counts.t")
save(counts.ts, file = "../counts.ts")
```

### Inspect read distribution before & after filtering

```{r}
# Plot distribution of unfiltered read counts across all samples 
#ggplotly(
ggplot(data = data.frame(rowMeans(counts)),
       aes(x = rowMeans.counts.)) +
  geom_histogram(fill = "grey") +
  xlim(1, 500) +
  theme_classic() +
  labs(title = "Distribution of unfiltered reads") +
  labs(y = "Density", x = "Raw read counts",
  title = "Read count distribution: untransformed, unnormalized, unfiltered\n(execept to remove 0's)")#)
```


START HERE


### Annotate genes with Uniprot IDs and Gene Ontology info 

### Create bed file for just genes, which I will use with getfasta to extract gene sequences, which I will use with blast to identify gene function

IMPORTANT NOTE: GFF format use a 1-based coordinate system, while BED format uses a 0-based coordinate system. I therefore need to convert my coordinates. 

```{r}
read_delim(file = "../../references/GCF_031168955.1_ASM3116895v1_genomic.gff", delim = "\t", col_names = F, skip = 9) %>% 
  mutate(X3=as.factor(X3)) %>% filter(X3=="gene") %>%
  select(X1, X4, X5, X9) %>%
  mutate(X4=X4-1) %>% #convert from 1-based to 0-based by subtracting 1 from the start position 
  mutate(X9=str_remove(X9, "ID=")) %>%
  select(X1,X4,X5,X9) %>%
  write.table(., "../../references/GCF_031168955.1_ASM3116895v1_genes.bed", sep = "\t",
              col.names = F, row.names = F, quote = F)
```
Use `bedtools getfasta` to get sequences of genes, then `blastx` to annotate them with Uniprot/Swissprot database. **NOTE: This was done on Sedna with the slurm script `blast_genes`** (saved to the /home/lspencer/references/pcod-ncbi/ directory). 

#### Import blast results (Uniprot/Swissprot annotated genes)

blastx output format 6 is tab file with the following columns: 
1. qaccver = Query accesion.version
2. saccver = Subject accession.version
3. pident = Percentage of identical matches
4. length = Alignment length
5. mismatch = Number of mismatches
6. gapopen = Number of gap openings
7. qstart = Start of alignment in query
8. qend = End of alignment in query
9. sstart =  Start of alignment in subject
10. send = End of alignment in subject
11. evalue =  Expect value
12. bitscore = Bit score

```{r}
# Blast results from the gadMor3.0 genome fasta + gff to pull gene sequences: "../references/gadMor3.0_genes_blastx.tab"

pcod.blast <- read_delim(file = "../references/GCF_031168955.1_ASM3116895v1_genes_blastx.tab", delim = "\t", 
                           col_names = c("qaccver", "saccver", "pident", "length", "mismatch", "gapopen", "qstart", "qend", "sstart", "send", "evalue", "bitscore")) %>%
  separate(qaccver, sep = ":|-", into = c("SeqID","Start","End")) %>%
  mutate_at(vars(Start, End), as.numeric) %>%
  separate(saccver, sep="\\|", into=c("na", "SPID", "gene.Uni"), remove = F) %>%
  dplyr::select(-na) %>% separate(gene.Uni, sep="_", into=c("gene.Uni", "species"), remove=T) %>%
  group_by(SeqID, Start, End) %>% dplyr::slice(which.min(evalue))  %>% # where multiple blast hits for same gene, select one with minimum e-value
  left_join(., read_delim(file="../references/gadMor3.0_genes.bed", delim="\t", col_names = c("SeqID", "Start", "End", "gene_info_gadmor"))) %>%
  dplyr::select(gene_info_gadmor, everything()) %>%
    separate(gene_info_gadmor, sep = ";", remove = F, 
             into = c("gene_na", "GeneID", "name", "gbkey", "gene_gadmor", "gene_biotype", "gene_synonym")) %>%  
    select(-gene_na,-name, -gbkey, -gene_biotype, -gene_synonym) %>%
    mutate(GeneID=gsub("Dbxref\\=GeneID:", "", GeneID), 
           gene_gadmor=gsub("gene\\=", "", gene_gadmor)) %>%
  clean_names()
  
  # E-VALUE FILTERING
# Count annotated genes with e-value filters
gadMor.blast %>% filter(evalue < 1.0e-10) %>% nrow() # 19,424 genes have e-value <1e-10
gadMor.blast %>% filter(evalue < 1.0e-15) %>% nrow() # 17,028 genes have e-value <1e-15
gadMor.blast %>% filter(evalue < 1.0e-20) %>% nrow() # 14,253 genes have e-value <1e-20

# Filter blast results to meet desired e-value threshold
gadMor.blast <- gadMor.blast %>% filter(evalue < 1.0e-10)

save(gadMor.blast, file = "../references/gadMor.blast")
load(file = "../references/gadMor.blast")
```

### Annotate with GO terms and other info

#### NOTE:  I needed GO IDs and gene functions, which weren't included in the blast file.  So I copied the column containing all Uniprot IDs from the P.plat.blast object, then pasted those into the tool Uniprot batch retrieval tool (https://www.uniprot.org/uploadlists/), and selected the columns: Entry, Entry name, Protein names, Gene names, Organism, Gene ontology (biological process), Gene ontology (cellular componenet), Gene ontology (molecular processes), Gene ontology (GO), Gene ontology Ids. I then downloaded all entries to a tab file, saved as: /references/gadMor_genes_GO.tsv. Now I'll read that into R and join with the P.plat.blast dataframe to link GO IDs with genes for exploration and enrichment analyses. 

```{r}
# Use this code to get list of Uniprot SPID (gene identifiers) to input into the Uniprot Batch Retrieval tool, to obtain GO terms for each gene
gadMor.blast %>% ungroup() %>% dplyr::select(spid) %>% distinct() %>%
  na.omit() %>% unlist() %>% as.vector() %>% write_clip()

# Add GO terms to Uniprot annotation object
gadMor.blast.GO <- left_join(gadMor.blast, read_delim(file = "../references/gadMor_genes_GO.tsv", 
                                                      delim = "\t") %>% clean_names(),
                             by = c("spid"="entry")) %>% ungroup()


save(gadMor.blast.GO, file = "../references/gadMor.blast.GO")
load(file = "../references/gadMor.blast.GO")

#View(gadMor.blast.GO)
```

### Annotate gene counts dataframe

```{r}
counts.annot.gadmor <- right_join(
  gadMor.blast %>% ungroup() %>% dplyr::select(gene_gadmor, spid, gene_uni, species, pident, evalue, gene_info_gadmor, seq_id, start, end, gene_id),
  counts.ts %>% t() %>% as.data.frame() %>% rownames_to_column("gene_gadmor"), "gene_gadmor") %>%
  left_join(gadMor.blast.GO %>% dplyr::select(gene_gadmor, protein_names, gene_names), "gene_gadmor") #%>%
  #dplyr::select(Chr, Start, End, Strand, Length, geneID, evalue, SPID, gene.Uni, species, pident, gene_names, protein_names, everything())

save(counts.annot.gadmor, file = "../results/star/counts.annot.gadmor")
write.csv(counts.annot.gadmor, file = "../results/counts_annotated_gadmor.csv", row.names = F, quote = F)
```

#### How many of our analyzed genes are annotated? Answer- 17,196

```{r}
right_join(
  gadMor.blast %>% ungroup() %>% dplyr::select(gene_gadmor, spid, gene_uni, species, pident, evalue),
  counts.ts %>% t() %>% as.data.frame() %>% rownames_to_column(var = "gene_gadmor"), "gene_gadmor") %>% filter(!is.na(spid)) %>%
  nrow()
```

#### Here's the total number of genes in the gadMor3.0 gff: 32,426 genes

```{r}
read_delim(file = "../references/genomic.gff", delim = "\t", col_names = F, skip = 8) %>% 
  mutate(X3=as.factor(X3)) %>% filter(X3=="gene")
```

```{r}
counts.ts %>% head(n=100) %>% View()
counts.annot.gadmor %>% head(n=100) #%>% View()
counts.annot.gadmor %>% head(n=100) %>% select(gene_gadmor, 
                                               PCG001, PCG004, PCG011, PCG015, PCG017, PCG020, PCG029, PCG035, 
                                               spid, species, evalue, protein_names) %>% View()
```

```{r}
gadMor.blast.GO %>% View()
```

